predict_objs (time t)
    for each object
        object.state(t) = object.predict_model(t)
    

class object_point_type
{
    location_type location;
    color_type color;
}

class object_move_type
{
    /*
        location change,
        send control signal to its joints
        communicating message
    */
    
    object_start_state;
    object_end_state;
        
    vector3 acceleration;
}

class relation_type
{
    location_type location;
    vector3 orientation;
    object_move_type calculate_object_move(relation_type)
    {
    }
}

class object_type
{
    list<object_point_type> points;
    list<relation_type> relations;
    
    predict_model(time t)
    {
       // todo: this prediction model is going to be used somewhere, but where?
        acceleration(t) = force/mass;
        velocity(t) = object.velocity(t_prev)+object.acceleration(t)*(t-t_prev);
        location(t) = location(t_prev) + velocity(t)*(t-t_prev);
    }
    
    add_relation(relation_type relation )
    {
        relations.push_back(relation);
    }
    
    add_point(object_point_type point)
    {
        points.add_point(point);
    }
    
    bool valid()
    {
        return (points.size()>threshold);
    }

    relation_type find_matching_relation(relation_type relation)
    {
    }
    
    update_state(object_move_type object_move)
    {
    }
    
    event_type calculate_event_from_relation_move(observed_scene_type observed_scene, relation_type relation)
    {
        relation_type matching_relation = find_matching_relation(relation);
        object_move_type object_move = matching_relation.calculate_object_move(relation);

        for (auto object_point in points) 
        {
            if (!observed_scene.contains_point(object_point.move(object_move))
                return null;
        }

        object.update_state(object_move);
        
        event_type event(object, object_move, observed_scene.time);
        return event;
    }    
}

class control_signal_type
{
    joint_type joint;
    signal_value_type value;
}

class event_type
{
    control_signal_type control_signal;
    object_type object;
    object_move_type move;
    time_type time;
    
    bool control_signal_event = false;
    
    event_type(object_type object, object_move_type move, time_type time)
    {
        this->object = object;
        this->move = move;
        this->time = time;
    }
    
    event_type(control_signal_type control_signal, time_type time)
    {
        this->control_signal = control_signal;
        this->time = time;
        control_signal_event = true;
    }
    
    bool occurred()
    {
        if (object.state == move.object_end_state)
            return true;
            
        return false;
    }
    
    execute_and_monitor()
    {
        if (control_signal_event)
        {
            send(control_signal.joint, control_signal.value);
            return;
        }
    }
}

class plan_type
{
    list<plan_type> plan_steps;
    
    event_type cause;
    event_type effect;
    //todo: need to add precondition? plan/prediction_model: object precondition and cause, object_move, object's end state (effect)

    bool terminal_node = false;
    
    certainty_counter = 0;
    
    
    //todo: add preconditions on cause and effect, necessary for the plan execution to start, f.e. cause and event objects have to be in contact for the move of one to cause the move of the other
    
    plan_type(event_type cause, event_type effect)
    {
        this->cause = cause;
        this->effect = effect;
        terminal_node = true;
    }
    
    add_step_to_plan(plan_type plan_step)
    {
        plan_steps.push_back(plan_step);
    }
    
    execute_and_monitor()
    {
        if (terminal_node)
        {
            cause.execute_and_monitor();
            if (effect.occurred())
                return;
            
            // todo: modify plan and possible plans to account for the unexpected plan outcome
            
            return;
        }
        for (plan_step in plan_steps)
        {
            plan_step.execute_and_monitor();
            
            if (effect.occurred())
                continue;
            
            // todo: modify plan and possible plans to account for the unexpected plan outcome
        }
    }
}

class observed_scene_type
{
    list <object_point_type> points;
    list <control_signal_type> control_signals;    
    
    list<relation_type> relations;
    time_type time;
    
    capture()
    {
        
    }
    
    calculate_relations()
    {
    }
    
    relation_type find_matching_relation(relation_type relation)
    {
    }
    
    bool contains_point(object_point_type point)
    {
    }
    
    event_type calculate_object_from_relation_move(observed_scene_type observed_scene, relation_type relation)
    {
        relation_type matching_relation = find_matching_relation(relation);
        object_move_type object_move = matching_relation.calculate_object_move(relation);
        object_type object;
        object.add_relation(relation);
        for (auto scene_point in points) 
        {
            if (observed_scene.contains_point(scene_point.move(object_move))
                object.add_point(scene_point);
        }
        
        event_type event(object, object_move, observed_scene.time);
        return event;
    }
}

class ai_system
{
    list <goal_type> goals;
    list <plan_type> possible_plans;
    list <plan_type> executed_plans;
    list <observed_scene_type> observed_scenes;    
    list <object_type> objects;
    list <event_type> events;
    
    lifecycle()
    {
        observe_world();
        learn_possible_plans();
        calculate_goals();
        assemble_plans_to_achieve_goals();
        execute_and_monitor_plans();
        /*  todo:
            cause_effect_sequences (aka plan) are executed no matter if ais wants it or not unless ais is physically participating in it by sending signal to its body or messaging a command to another ais.
            ais monitors if the world changes according to its predictions (through cause_effect_sequences) and modifies them as necessary
            ais can form complex signals into symbols or messages to communicate with other aises and interpret the symbols and messages received from other aises.
            sensors: visual (location, color; objects, moving in space, changing color), 
                        characters, words, sentences, symbols
                     tactile (location, temperature; objects moving in space, changing temperature), 
                     auditory (location, sound pitch and level; objects moving in space, generate sound of various pitch and level)
                        characters, words, sentences are coded relations; 
                        the relations can encode events, including objects and object moves
            control signals:
                muscle signal to move a body part;
                characters, words, sentences to send visual, tactile, auditory messages
            tracking the changes of the objects of interest (maybe adding goals to track the objects?)
            analyzing the objects of inteterest (curiosity, maybe by adding "curiosity" goals?)
         */
    }

    observe_world()
    {
        observed_scene_type observed_scene;
        observed_scene.capture();
        observed_scene.calculate_relations();
        observed_scenes.push_back();
    }    
    
    learn_possible_plans() 
    {
        observed_scene_type observed_scene = observed_scenes.back();
        get_events_from_matching_observed_scene_relation_to_existing_objects();
        get_events_from_matching_observed_scene_relation_to_previous_scenes();  
        
        get_control_signal_events();
        
        get_new_and_correct_existing_possible_plans_from_events();
    }
    
    get_new_and_correct_existing_possible_plans_from_events()
    {
        for (event_type cause in events)
        {
            for (event_type effect in events)
            {
                if (cause.time < effect.time)
                {
                    if (possible_plans[cause].effect != effect)
                    {
                        possible_plans[cause].certainty_counter--;
                        
                        plan_type possible_plan(cause, effect);
                        possible_plans.push_back(possible_plan);
                    } 
                    else
                    {
                        possible_plans[cause].certainty_counter++;                    
                    }
                  
                }
            }
        }
    }

    get_control_signal_events()
    {
        observed_scene_type observed_scene = observed_scenes.back();
        
        for (control_signal in observed_scene.control_signals)
        {
            event_type event(observed_scene.control_signal, observed_scene.time);
            events.push_back(event);                
        }
    }
    
    get_events_from_matching_observed_scene_relation_to_existing_objects()
    {
        observed_scene_type observed_scene = observed_scenes.back();
        for (relation in observed_scene.relations)
        {
            for (object in objects)
            {
              event_type event = object.calculate_event_from_relation_move(observed_scene, relation);
              events.push_back(event);                
            }
        }    
    }
    
    get_events_from_matching_observed_scene_relation_to_previous_scenes()
    {
        auto it = observed_scenes.rbegin();
        observed_scene_type observed_scene = *it++;
        observed_scene_type prev_observed_scene = *it;
        
        for (relation in observed_scene.relations)
        {
            event_type event = prev_observed_scene.calculate_object_from_relation_move(observed_scene, relation);
            events.push_back(event);
            objects.push_back(object);
            // todo: environment as an object, an object is a part of another object, event, causality between events
        }
    }
    
    assemble_plans_to_achieve_goals()
    {
        for (goal in goals) 
        {
            plan_type plan;
            subgoal = goal;
            while (!achieved(subgoal))
            {
                plan_step = get_plan_by_effect(subgoal);
                plan.add_step_to_plan(plan_step);
                subgoal = plan_step.cause;
            }
            plans.push_back(plan);
        }
    }

    execute_and_monitor_plans();
    {
        for (plan in executed_plans) 
        {
            plan.execute_and_monitor();
        }
    }

    plan_type get_plan_by_effect(event_type effect)
    {
        for (plan in possible_plans) 
        {
            if (plan.effect == effect)
                return plan_step;
        }
        return null;
    }
    
    predict_world();
    calculate_goals();
}


Detection algorithm:


input sensor data frame (scene);
match_observed_scene_relation_to_existing_objects
match_observed_scene_relation_to_previous_scenes


match_observed_scene_relation_to_existing_objects

for each obj having a detected rel
    for each subset of rels which satisfy the obj rel poses
        find transform between obj and scene
        if the scene data and obj after transform are color compatible
            the object is identified
        else if the scene data and obj after transform are partially color compatible
        
        exceptions:
            break;
        
        
        
