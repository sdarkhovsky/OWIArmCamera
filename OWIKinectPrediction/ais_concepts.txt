Object representation:

Rel1 (pose)
...
RelN (pose)

Pnts (Clr,X)

Poses and X are in the obj RF.



predict_objs (time t)
    for each object
        object.state(t) = object.predict_model(t)
    

class state_type
{
    location;
    velocity;
    acceleration;
}

class object_move_type
{
}

class object_type
{
    map(time_type, state_type) state;
    
    predict_model(time t)
    {
        acceleration(t) = force/mass;
        velocity(t) = object.velocity(t_prev)+object.acceleration(t)*(t-t_prev);
        X(t) = X(t_prev) + velocity(t)*(t-t_prev);
    }
}

class event_type
{
    object_type object;
    object_move_type move;
    
    execute()
    {
        object.move();
    }
}

class action_type
{
    cause_type cause;
    effect_type effect;
    actuator_signal;
    
    execute()
    {
        send(actuator_signal);
    }
}

class plan_type
{
    list<plan_type> plan_steps;
    
    event_type cause;
    event_type effect;
    
    add_step_to_plan(plan_type plan_step)
    {
        plan_steps.push_back(plan_step);
    }
    
    execute()
    {
        for (plan_step in plan_steps)
        {
            plan_step.execute();
        }
        cause.execute();
    }
}

class observed_scene_type
{
    sensor_data;
}

class ai_system
{
    list<goal_type> goals;
    list <plan_type> possible_plans;
    list <plan_type> executed_plans;
    list<observed_scene_type> observed_scenes;    
    
    lifecycle()
    {
        observe_world();
        learn_possible_plans();
        calculate_goals();
        assemble_plans_to_achieve_goals();
        execute_plans();
    }

    observe_world()
    {
        observed_scene_type observed_scene;
        input_sensor_data(observed_scene);
        observed_scenes.push_back();
    }    
    
    learn_possible_plans() 
    {
    
        observed_scene.calculate_relations();
        11111111111111111111111111111111111111
        learn_possible_actions(observed_scene);    
    111111111111111111111
        identify_objects(observed_scene);
        match_observed_scene_relation_to_existing_objects();
        match_observed_scene_relation_to_previous_scenes();    
    }
    
    assemble_plans_to_achieve_goals()
    {
        for (goal in goals) 
        {
            plan_type plan;
            subgoal = goal;
            while (!achieved(subgoal))
            {
                plan_step = get_plan_by_effect(subgoal);
                plan.add_step_to_plan(plan_step);
                subgoal = plan_step.cause;
            }
            plans.push_back(plan);
        }
    }

    execute_plans();
    {
        for (plan in executed_plans) 
        {
            plan.execute();
        }
    }

    plan_type get_plan_by_effect(event_type effect)
    {
        for (plan in possible_plans) 
        {
            if (plan.effect == effect)
                return plan_step;
        }
        return null;
    }
    
    predict_world();
    calculate_goals();
}


Detection algorithm:


input sensor data frame (scene);
match_observed_scene_relation_to_existing_objects
match_observed_scene_relation_to_previous_scenes


match_observed_scene_relation_to_existing_objects

for each obj having a detected rel
    for each subset of rels which satisfy the obj rel poses
        find transform between obj and scene
        if the scene data and obj after transform are color compatible
            the object is identified
        else if the scene data and obj after transform are partially color compatible
        
        exceptions:
            break;
        
        
        
